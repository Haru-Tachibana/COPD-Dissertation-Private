{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b80bb196-a732-4151-b0c4-281766a110bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "464fe0ce-2767-47f8-a0a3-ec2cf6e6e218",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import collect_list, concat_ws, udf ,lit, col, when, split, size, lower, explode, dayofmonth\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col, when, lit, avg, stddev, month, year, unix_timestamp\n",
    "#from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from xgboost.spark import SparkXGBRegressor as XGBRegressor\n",
    "from xgboost.spark import SparkXGBClassifier as XGBClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\n",
    "from pyspark.sql import DataFrame\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3a2ac24-a337-4851-b061-110eb57ac608",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Loading a native XGBoost model with Scikit-Learn interface.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd085300-99fb-44e7-88f3-7999cedbda6d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. rmse - min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73a8e78f-fc82-4426-b4d8-c26e1d771270",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"n_estimators\": 1000,\n",
    "        \"verbosity\": 0,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "    }\n",
    "\n",
    "    xgb = XGBRegressor(\n",
    "        features_col=\"features\", label_col=\"storedelivery%_label_col\", **params\n",
    "    )\n",
    "\n",
    "    model = xgb.fit(train_df)\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    evaluator_rmse = RegressionEvaluator(\n",
    "        labelCol=\"storedelivery%_label_col\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"rmse\",\n",
    "    )\n",
    "\n",
    "    rmse = evaluator_rmse.evaluate(predictions)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f791c752-6819-401d-8cf0-acc372b8499a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. R2 - max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f4324f0-08c9-44d3-8e1c-30acc84883f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"n_estimators\": 2500,\n",
    "        \"verbosity\": 0,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 7),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 5, 15),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.2, 0.7),\n",
    "    }\n",
    "\n",
    "    xgb = SparkXGBRegressor(features_col=\"features\", label_col=\"label\", **params)\n",
    "\n",
    "    model = xgb.fit(train_df)\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    evaluator_r2 = RegressionEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"r2\",\n",
    "    )\n",
    "\n",
    "    r2 = evaluator_r2.evaluate(predictions)\n",
    "    return r2\n",
    "\n",
    "study = create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best RÂ²:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4d76d01-28cc-4a97-b391-057cd599a472",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb805d9c-4417-4fdc-85be-03f5678b5de4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def xgb_evaluate(model, model_name, train_df, test_df, feature_columns, params=None):\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "    if params:\n",
    "        for key, value in params.items():\n",
    "            model.setParam(key, value)\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, model])\n",
    "    pipeline_model = pipeline.fit(train_df)\n",
    "    predictions = pipeline_model.transform(test_df)\n",
    "\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"rmse\",\n",
    "    )\n",
    "\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "    print(f\"{model_name} - RMSE: {rmse}, R2: {r2}\")\n",
    "    xgb_feature_importance(pipeline_model, model_name, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d421f35c-2c7b-4335-9692-87be6fe494d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"learningRate\": 0.0043,\n",
    "    \"maxDepth\": 6,\n",
    "    \"subsample\": 0.7372,\n",
    "    \"colsampleBytree\": 0.785,\n",
    "    \"minChildWeight\": 6,\n",
    "    \"alpha\": 0.5725,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"numRound\": 2500,\n",
    "}\n",
    "\n",
    "exclude_columns = [\"label\"]\n",
    "\n",
    "if \"features\" in df_xgb.columns:\n",
    "    df_xgb = df_xgb.drop(\"features\")\n",
    "\n",
    "feature_columns = get_all_column_names(df_xgb, exclude_columns)\n",
    "train_df, test_df = df_xgb.randomSplit([0.7, 0.3], seed=27)\n",
    "\n",
    "xgb_model = XGBRegressor(label_col=\"label\")\n",
    "xgb_model.setParams(**xgb_params)\n",
    "\n",
    "xgb_evaluate(xgb_model, \"XGBoost\", train_df, test_df, feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fe78531-eeb9-4210-98fc-7733cac6c20c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Visualisation\n",
    "[optuna web](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a0e2f8c-cd3d-4de8-9b9a-b2fc16083591",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import optuna\n",
    "\n",
    "# You can use Matplotlib instead of Plotly for visualization by simply replacing `optuna.visualization` with\n",
    "# `optuna.visualization.matplotlib` in the following examples.\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_rank\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a7d0d27-1199-47e3-9668-a08711620b59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "without tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f9d19a3-a4e8-4a2b-8b28-45ca631ee105",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def xgb_feature_importance(model, model_name, feature_columns):\n",
    "    booster = model.stages[-1].get_booster()\n",
    "    xgb_feature_importance_dict = booster.get_score(importance_type=\"weight\")\n",
    "    importance = [\n",
    "        xgb_feature_importance_dict.get(f\"f{i}\", 0.0)\n",
    "        for i in range(len(feature_columns))\n",
    "    ]\n",
    "    xgb_feature_importance_list = list(zip(feature_columns, importance))\n",
    "    xgb_feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Feature Importances for {model_name}:\")\n",
    "    for feature, importance in xgb_feature_importance_list:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "    print()\n",
    "\n",
    "def xgb_evaluate(model, model_name, train_df, test_df, feature_columns):\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, model])\n",
    "    pipeline_model = pipeline.fit(train_df)\n",
    "    predictions = pipeline_model.transform(test_df)\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=\"storedelivery%_label_col\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    "    )\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "    print(f\"{model_name} - RMSE: {rmse}, R2: {r2}\")\n",
    "    xgb_feature_importance(pipeline_model, model_name, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6798434-69eb-4f73-b1b5-50213bd0a57e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 'features' in df.columns: df_3 = df_3.drop('features')\n",
    "\n",
    "feature_columns = get_all_column_names(df_3, exclude_columns)\n",
    "train_df, test_df = df_3.randomSplit([0.7, 0.3], seed=27)\n",
    "xgb_4 = SparkXGBRegressor(features_col=\"scaledFeatures\", label_col=\"storedelivery%_label_col\")\n",
    "xgb_evaluate(xgb_4, \"XGBoost\", train_df, test_df, feature_columns)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Optuna Useful Functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
